{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom ggplot import *\nimport glob\nimport os\nimport re\nimport fnmatch",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from IPython.display import display\nimport matplotlib.lines as mlines\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom statsmodels.formula.api import ols\nimport seaborn as sns\nimport string",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#the list of training & testing fnames\nfnames = sorted(glob.glob('*.csv'))\ntraining_files = [fname for fname in fnames if re.match('(\\d*)_main_exp_(\\w*)_(\\w*)_(\\w*)_(\\d*_\\w*_\\d*)_(\\d*)_data.csv', fname)]\ntesting_files = [fname for fname in fnames if re.match('(\\d*)_main_exp_(\\w*)_(\\w*)_(\\w*)_(\\d*_\\w*_\\d*)_(\\d*).csv', fname)]",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#adding file_name colomn to each file\nlist_of_dfs = [pd.read_csv(fname) for fname in training_files]\nfor dataframe, fname in zip(list_of_dfs, training_files):\n    dataframe['file_name'] = fname",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Combine a list of dataframes, on top of each other\ntraining = pd.concat(list_of_dfs, ignore_index=True)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#merging block_order, block_order_bytype to each training file\ninfo = pd.read_csv(\"training_fnames_info.csv\")\ntraining_data = pd.merge(training,\n                 info[['file_name', 'block_order', 'block_order_bytype','subj_id']],\n                 on ='file_name')\ntraining_data = training_data.sort_values(by = ['subj_id','block_order'])\ntraining_data = training_data.reset_index(drop = True)\ntraining_data.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pic_index</th>\n      <th>trial_num</th>\n      <th>pic_name</th>\n      <th>rt</th>\n      <th>resp</th>\n      <th>feedback_code</th>\n      <th>feedback</th>\n      <th>segment</th>\n      <th>segment_index</th>\n      <th>pic_type</th>\n      <th>trial_target</th>\n      <th>file_name</th>\n      <th>block_order</th>\n      <th>block_order_bytype</th>\n      <th>subj_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>lion</td>\n      <td>3.416950</td>\n      <td>space</td>\n      <td>1</td>\n      <td>correct</td>\n      <td>target</td>\n      <td>NaN</td>\n      <td>targetNaN</td>\n      <td>lion</td>\n      <td>01_main_exp_training_lion_wbuilder_2018_Oct_16...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>coffeepot</td>\n      <td>4.300220</td>\n      <td>left</td>\n      <td>1</td>\n      <td>correct</td>\n      <td>path</td>\n      <td>1.0</td>\n      <td>path1</td>\n      <td>lion</td>\n      <td>01_main_exp_training_lion_wbuilder_2018_Oct_16...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>mosquito</td>\n      <td>1.366912</td>\n      <td>left</td>\n      <td>1</td>\n      <td>correct</td>\n      <td>path</td>\n      <td>2.0</td>\n      <td>path2</td>\n      <td>lion</td>\n      <td>01_main_exp_training_lion_wbuilder_2018_Oct_16...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>canoe</td>\n      <td>0.750253</td>\n      <td>right</td>\n      <td>1</td>\n      <td>correct</td>\n      <td>path</td>\n      <td>3.0</td>\n      <td>path3</td>\n      <td>lion</td>\n      <td>01_main_exp_training_lion_wbuilder_2018_Oct_16...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>goose</td>\n      <td>7.783490</td>\n      <td>right</td>\n      <td>1</td>\n      <td>correct</td>\n      <td>decision</td>\n      <td>1.0</td>\n      <td>decision1</td>\n      <td>lion</td>\n      <td>01_main_exp_training_lion_wbuilder_2018_Oct_16...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   pic_index  trial_num   pic_name        rt   resp  feedback_code feedback  \\\n0          1          1       lion  3.416950  space              1  correct   \n1          2          1  coffeepot  4.300220   left              1  correct   \n2          3          1   mosquito  1.366912   left              1  correct   \n3          4          1      canoe  0.750253  right              1  correct   \n4          5          1      goose  7.783490  right              1  correct   \n\n    segment  segment_index   pic_type trial_target  \\\n0    target            NaN  targetNaN         lion   \n1      path            1.0      path1         lion   \n2      path            2.0      path2         lion   \n3      path            3.0      path3         lion   \n4  decision            1.0  decision1         lion   \n\n                                           file_name  block_order  \\\n0  01_main_exp_training_lion_wbuilder_2018_Oct_16...          1.0   \n1  01_main_exp_training_lion_wbuilder_2018_Oct_16...          1.0   \n2  01_main_exp_training_lion_wbuilder_2018_Oct_16...          1.0   \n3  01_main_exp_training_lion_wbuilder_2018_Oct_16...          1.0   \n4  01_main_exp_training_lion_wbuilder_2018_Oct_16...          1.0   \n\n   block_order_bytype  subj_id  \n0                 1.0        1  \n1                 1.0        1  \n2                 1.0        1  \n3                 1.0        1  \n4                 1.0        1  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#learning criterion for each subject each block\ndef trial_criteria (subj_id,block,criteria):\n    \n    # select specific subject and block data from trainig_data\n    subj_acc = training_data.loc[training_data.subj_id == subj_id]\n    block_data = subj_acc.loc[subj_acc.block_order == block]\n    block_data = block_data.reset_index(drop = True)\n    \n    #create a new dataframe that has column of trial_num and percentage of correct feedback\n    #for each trial\n    block_criteria = pd.DataFrame(columns = ['trial_num','feedback_sum'])\n    \n    # Get the percentage of correct feedback for each trial\n    feedback_sum = []\n    for i in range (1,block_data['trial_num'].iloc[-1]+1): # <------- use trial_num as a indicator for iterating through rows\n        trial_sum = (block_data.loc[block_data['trial_num'] == i, 'feedback_code'].sum())/12\n        feedback_sum.append(trial_sum)\n        i += 1 \n    block_criteria['trial_num'] = np.arange(len(feedback_sum)) + 1\n    block_criteria['feedback_sum'] = feedback_sum\n\n    #count the correct number of trials \n    correct = 0 \n    percent = 0\n    correct_count = []\n    correct_percent = []\n    for i in range (0,len(block_criteria)-(criteria-1)):\n        iterate_trial = (block_criteria.iloc[i:(i+criteria)])['feedback_sum']\n        for iterate_rows in iterate_trial:\n            if iterate_rows == 1:\n                correct += 1\n                percent = correct / criteria\n        correct_count.append(correct)\n        correct_percent.append(percent)\n        correct = 0\n        percent = 0\n    \n    #create a new dataframe that has trial_num, overall_percentage\n    overall_criteria = pd.DataFrame(columns = ['trial_criteria','overall_data'])\n    overall_criteria['trial_criteria'] = np.arange(len(block_criteria['trial_num'])-(criteria-1)) + 1\n    overall_criteria['overall_data'] = correct_count\n    overall_criteria['trial_target'] = block_data['trial_target'][0] \n    overall_criteria['count'] = correct_count\n    overall_criteria['trial_sq'] = overall_criteria['trial_criteria']**2\n\n    return overall_criteria",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trial_criteria (subj_id = 4,block = 4,criteria = 10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def trial_criteria_graph(subj_id,criteria):\n    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n    plt.title('trial accuracy criteria = ' + str(criteria),loc = 'center')\n    for j in range(1,5):\n        overall_criteria = trial_criteria (subj_id,j,criteria)\n\n        #get regression line for learning criteria\n        #change sigmoid    \n        formula_criteria = 'overall_data ~ trial_sq + trial_criteria'\n        mod = ols(formula=formula_criteria, data=overall_criteria)\n        results = mod.fit()\n        #print(results.summary())\n        predicted = results.predict()\n        #print(predicted)\n\n        # scatter plot of learning criteria\n        target = overall_criteria['trial_target'][0]\n        if target == \"arc\":\n            target = \"beaver\"\n        elif target == \"bolt\":\n            target = \"lion\"\n        axes[j-1].scatter(overall_criteria['trial_criteria'],overall_criteria['overall_data'],label = 'subj_' + str(subj_id) \\\n                + ', block ' + str(j) + ', ' + 'criteria = ' + str(criteria) + ', '+ target )\n        axes[j-1].plot(overall_criteria['trial_criteria'], predicted, linewidth = 3) # <------------- Add predicted values\n        axes[j-1].set_xlabel('trial bins') # <--------------- Set x axis label\n        axes[j-1].legend(loc = \"lower right\")\n        plt.yticks(np.arange(0, 1.2, step=0.2))\n        axes[j-1].set_ylim(0, 1)\n        axes[j-1].set_ylabel('Accuracy(percentage)') # <--------- Set y axis label\n        j += 1\n       \n    #save subplots for each subject\n    #plt.savefig('subj'+str(subj_id)+ '_criteria' + str(criteria) + '_trial_criteria.png')\n    #plt.close() \n",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trial_criteria_graph(subj_id = 1,criteria = 5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def trial_response_time(subj_id,block,criteria):\n     # select specific subject and block data from trainig_data\n    subj_acc = training_data.loc[training_data.subj_id == subj_id]\n    block_data = subj_acc.loc[subj_acc.block_order == block]\n    block_data = block_data.reset_index(drop = True)\n    \n    #create a new dataframe that has column of trial_num and percentage of correct feedback\n    #for each trial\n    block_rt = pd.DataFrame(columns = ['trial_num','rt'])\n    \n    # Get the percentage of correct feedback for each trial\n    rt_mean = []\n    for i in range (1,block_data['trial_num'].iloc[-1]+1): # <------- use trial_num as a indicator for iterating through rows\n        rt = (block_data.loc[block_data['trial_num'] == i, 'rt'].sum())\n        rt_mean.append(rt)\n        i += 1 \n    block_rt['trial_num'] = np.arange(len(rt_mean)) + 1\n    block_rt['rt'] = rt_mean\n    \n    #average rt for each criteria\n    rt_criteria = []\n    for i in range (0,len(block_rt)-(criteria-1)):\n        iterate_trial = (block_rt.iloc[i:(i+criteria)])['rt']\n        rt_mean = iterate_trial.sum()/ criteria\n        rt_criteria.append(rt_mean)\n        \n    #create a new dataframe that has trial_num, overall_percentage\n    overall_rt = pd.DataFrame(columns = ['trial_criteria','rt_mean'])\n    overall_rt['trial_criteria'] = np.arange(len(block_rt['trial_num'])-(criteria-1)) + 1    \n    overall_rt['rt_mean'] = rt_criteria\n    overall_rt['trial_sq'] = block_rt['trial_num'] ** 2\n    return overall_rt\n#trial_response_time(subj_id = 5,block=1,criteria = 5)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit \nimport scipy.optimize as optimize\ndef trial_rt_criteria_graph(subj_id,criteria):\n    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n    plt.title('all trials rt criteria = ' + str(criteria),loc = 'center')\n    for j in range(1,5):\n        overall_criteria = trial_criteria (subj_id,j,1,criteria)\n        rt_criteria = trial_response_time(subj_id = subj_id,block = j,criteria = criteria)\n        \n        # log formula\n        def func(t, a, b):\n            return a + b * np.log(t)\n        popt, pcov = optimize.curve_fit(func,rt_criteria['trial_criteria'] , rt_criteria['rt_mean'], maxfev=5000)\n        t = rt_criteria['trial_criteria']\n        \n        target = overall_criteria['trial_target'][0]\n        if target == \"arc\":\n            target = \"beaver\"\n        elif target == \"bolt\":\n            target = \"lion\"\n        \n        #set up x_lim & y_lim\n        if (j == 1) | (j == 2):\n            max_rt1 = max(trial_response_time(subj_id = subj_id,block = 1,criteria = criteria)['rt_mean'])\n            max_rt2 = max(trial_response_time(subj_id = subj_id,block = 2,criteria = criteria)['rt_mean'])\n            if max_rt1 > max_rt2:\n                max_rt = max_rt1\n            else:\n                max_rt = max_rt2\n        elif (j == 3) | (j == 4):\n            max_rt3 = max(trial_response_time(subj_id = subj_id,block = 3,criteria = criteria)['rt_mean'])\n            max_rt4 = max(trial_response_time(subj_id = subj_id,block = 4,criteria = criteria)['rt_mean'])\n            if max_rt3 > max_rt4:\n                max_rt = max_rt3\n            else:\n                max_rt = max_rt4\n        plt.yticks(np.arange(0,(max_rt + 1),step=(max_rt / 5)))\n        axes[j-1].set_xlabel('trial bins') # <--------------- Set x axis label\n        axes[j-1].set_ylim(0, max_rt)\n        axes[j-1].set_ylabel('response time(average)') # <--------- Set y axis label\n        axes[j-1].scatter(rt_criteria['trial_criteria'],rt_criteria['rt_mean'],label = 'subj_' + str(subj_id) \\\n                + ', block ' + str(j) + ', ' + 'criteria = ' + str(criteria) + ', ' + target + ', rt' ,color = 'green')\n        axes[j-1].plot(rt_criteria['trial_criteria'], func(rt_criteria['trial_criteria'],*popt),\n                       linewidth = 3,color = 'green',label = 'best fit') # <------------- Add predicted values\n        axes[j-1].legend(loc = \"lower right\")\n        j += 1\n       \n    \n    #save subplots for each subject\n    #plt.savefig('subj'+str(subj_id)+ '_criteria' + str(criteria) + '_trial_rt.png')\n    #plt.close() \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "trial_rt_criteria_graph(subj_id = 6,criteria = 10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def rt_trials_graph(subj_id,criteria):\n    trial_criteria_graph(subj_id = subj_id,criteria = criteria)\n    trial_rt_criteria_graph(subj_id = subj_id,criteria = criteria)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def rt_trials_subjects(subject):\n    criteria = 10\n    for i in range(1,subject+1):\n        rt_trials_graph(subj_id = i,criteria = criteria)\n#rt_trials_subjects(30)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}